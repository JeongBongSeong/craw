from craw_driver import Craw_Driver
from craw_info import Acc_info
from bs4 import BeautifulSoup as bs
import os
import time
import hashlib
import json
import pickle
from multiprocessing import Pool,Process

#import urllib.request
#import threading

class malwares:
    _chrome_driver = None #d_river 클래스용
    _craw_info = None #acc_info 클래스용
    _url = None
    _url_hash = None

    def malwares_run(self):
        #self.hide()
        self._craw_info = Acc_info(get_url='https://www.malwares.com/search/tag?tag=pharming')
        self._chrome_driver = Craw_Driver()
        self._chrome_driver.driver_run()


        self._chrome_driver._driver.get(self._craw_info.get_url())
        time.sleep(5)
        
        _click = self._chrome_driver._driver.find_element_by_xpath('//*[@id="header"]/div[2]/ul[1]/li[2]')
        
        self._chrome_driver._driver.execute_script("arguments[0].click();",_click)
        self._chrome_driver._driver.find_element_by_name('lgn_email').send_keys('jbs@stsc.com')
        self._chrome_driver._driver.find_element_by_name('lgn_passwd').send_keys('tlsrudrhkals1!')
        self._chrome_driver._driver.find_element_by_xpath('//*[@id="login_layer"]/li[6]/span').click()
        
        time.sleep(5)
        
        _soup = bs(self._chrome_driver._driver.page_source,'html.parser')
        _soup = _soup.findAll("span",class_ = 'data cursor')
        
        self._url = 'https://www.malwares.com/report/file?hash='
        
        for _i in _soup:
            self._url_hash = _i.get_text()
            self._chrome_driver._driver.get(self._url+self._url_hash)
            self._chrome_driver._driver.find_element_by_xpath('//*[@id="file_download"]').click()
        # urllib.request.urlretrieve(i,filePath+i)

        time.sleep(5)

        self._chrome_driver._driver.close()
    

        for _i in _soup:
            self._url_hash = _i.get_text()
            print(self.down_path+self.url_hash)
            self.hash_test(self.url_hash)
        try:
            soup = bs(self._chrome_driver._driver.page_source,'html.parser')
        except Exception as e:
            print(e)

### 사용한다면 이 부분도 빼서 사용해야 할 듯
    def hash_test(self,file_name): #hash_test함수는 파일 해시참고해서 이름바꾸는데 사용하지만 사용안함
        f = open(down_path+file_name, 'rb')
        data = f.read()
        f.close()

        self.md5 = hashlib.md5(data).hexdigest()
        self.sha_1 = hashlib.sha1(data).hexdigest()
        self.sha_256 = hashlib.sha256(data).hexdigest()
        self.f_size = str(os.stat(self.down_path+file_name).st_size)

        #os.rename(file_name,self.sha_256) #malwares는 이미 해쉬값
        
        print("MD5: " + self.md5)
        print("SHA-1: " + self.sha_1)
        print("SHA-256: " + self.sha_256)
        print("file_size: "+ self.f_size+" bytes")
if __name__ =='__main__':
    malware = malwares()
    malware.malwares_run()